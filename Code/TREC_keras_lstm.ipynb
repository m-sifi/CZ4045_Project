{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 19:27:26.884827: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adagrad, Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.downloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size:  3861\n",
      "Development Size:  500\n",
      "Test Size:  1091\n"
     ]
    }
   ],
   "source": [
    "path = '../Datasets/Processed/TREC'\n",
    "\n",
    "training_dev_df = pd.read_csv(f'{path}/train.dev.csv')\n",
    "training_df = pd.read_csv(f'{path}/train.csv')\n",
    "test_df = pd.read_csv(f'{path}/test.csv')\n",
    "print(\"Training Size: \", training_df.shape[0])\n",
    "print(\"Development Size: \", training_dev_df.shape[0])\n",
    "print(\"Test Size: \", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "training_encoded_labels = label_encoder.fit_transform(training_df['label-coarse'])\n",
    "dev_encoded_labels = label_encoder.fit_transform(training_dev_df['label-coarse'])\n",
    "test_encoded_labels = label_encoder.fit_transform(test_df['label-coarse'])\n",
    "\n",
    "training_df['label-coarse'] = training_encoded_labels\n",
    "training_dev_df['label-coarse'] = dev_encoded_labels\n",
    "test_df['label-coarse'] = test_encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '2': 1, '3': 2, '5': 3, 'OTHERS': 4}\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "print(label_mapping)\n",
    "num_labels = len(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_texts(training_dev_df['text'])\n",
    "tokenizer.fit_on_texts(training_df['text'])\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(training_df['text'])\n",
    "X_val_sequences = tokenizer.texts_to_sequences(training_dev_df['text'])\n",
    "X_test_sequences = tokenizer.texts_to_sequences(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.downloader.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  6884\n",
      "Embedding Size:  300\n",
      "Voc Size:  6884\n",
      "Max Sentence Len:  194\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained Model\n",
    "pretrained_weights = w2v_model.vectors\n",
    "google_vocab_size, embedding_size = pretrained_weights.shape\n",
    "\n",
    "voc = tokenizer.word_index\n",
    "vocab_size = len(voc) + 1\n",
    "word2idx = {k: v for v, k in enumerate(voc)}\n",
    "\n",
    "max_sentence_len = max([len(s) for s in training_df['text']])\n",
    "\n",
    "print(\"Vocab Size: \", vocab_size) # vocab size taken from training dataset\n",
    "print(\"Embedding Size: \", embedding_size)\n",
    "print(\"Voc Size: \", vocab_size)\n",
    "print(\"Max Sentence Len: \", max_sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embedding_size))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model:\n",
    "        embedding_matrix[i] = w2v_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "sequence_length = max_sentence_len  # Choose an appropriate sequence length (follow the pretrain)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=sequence_length, padding='post')\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=sequence_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=sequence_length, padding='post')\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "y_train = to_categorical(training_df['label-coarse'])\n",
    "y_val = to_categorical(training_dev_df['label-coarse'])\n",
    "y_test = to_categorical(test_df['label-coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 194, 300)          2065200   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 256)               439296    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 300)               77100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 1505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2583101 (9.85 MB)\n",
      "Trainable params: 2583101 (9.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = num_labels\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_size, \n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_sentence_len,\n",
    "                    embeddings_initializer=k.initializers.Constant(embedding_matrix))\n",
    "        )\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=128, \n",
    "                dropout=0.5, \n",
    "                recurrent_dropout=0.5, \n",
    "                kernel_initializer=k.initializers.he_normal()\n",
    "                )\n",
    "        ))\n",
    "\n",
    "model.add(Dense(units=embedding_size, activation= \"relu\", kernel_regularizer=regularizers.L1L2(l1=0.0025, l2=0.0025)))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.3341 - accuracy: 0.4437\n",
      "Epoch 1: accuracy improved from -inf to 0.44367, saving model to ../Models/Question_Classification/questions_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregorywng6gmail.com/Desktop/CZ4045/Project/project_env/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 54s 2s/step - loss: 9.3341 - accuracy: 0.4437 - val_loss: 6.4543 - val_accuracy: 0.6320\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.6788 - accuracy: 0.6869\n",
      "Epoch 2: accuracy improved from 0.44367 to 0.68687, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 48s 2s/step - loss: 4.6788 - accuracy: 0.6869 - val_loss: 2.9395 - val_accuracy: 0.8060\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0295 - accuracy: 0.8063\n",
      "Epoch 3: accuracy improved from 0.68687 to 0.80627, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 2.0295 - accuracy: 0.8063 - val_loss: 1.2578 - val_accuracy: 0.8220\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.9188 - accuracy: 0.8617\n",
      "Epoch 4: accuracy improved from 0.80627 to 0.86169, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.9188 - accuracy: 0.8617 - val_loss: 0.7596 - val_accuracy: 0.8720\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.9042\n",
      "Epoch 5: accuracy improved from 0.86169 to 0.90417, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.6034 - accuracy: 0.9042 - val_loss: 0.6617 - val_accuracy: 0.8540\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4740 - accuracy: 0.9285\n",
      "Epoch 6: accuracy improved from 0.90417 to 0.92852, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.4740 - accuracy: 0.9285 - val_loss: 0.6132 - val_accuracy: 0.8500\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.9464\n",
      "Epoch 7: accuracy improved from 0.92852 to 0.94639, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.3964 - accuracy: 0.9464 - val_loss: 0.6562 - val_accuracy: 0.8520\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3368 - accuracy: 0.9630\n",
      "Epoch 8: accuracy improved from 0.94639 to 0.96296, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.3368 - accuracy: 0.9630 - val_loss: 0.5964 - val_accuracy: 0.8500\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.9650\n",
      "Epoch 9: accuracy improved from 0.96296 to 0.96503, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.2985 - accuracy: 0.9650 - val_loss: 0.5623 - val_accuracy: 0.8520\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9798\n",
      "Epoch 10: accuracy improved from 0.96503 to 0.97980, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.2520 - accuracy: 0.9798 - val_loss: 0.6137 - val_accuracy: 0.8480\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9829\n",
      "Epoch 11: accuracy improved from 0.97980 to 0.98291, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.2310 - accuracy: 0.9829 - val_loss: 0.6334 - val_accuracy: 0.8420\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9829\n",
      "Epoch 12: accuracy did not improve from 0.98291\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.2332 - accuracy: 0.9829 - val_loss: 0.6638 - val_accuracy: 0.8540\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9883\n",
      "Epoch 13: accuracy improved from 0.98291 to 0.98834, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.1974 - accuracy: 0.9883 - val_loss: 0.6149 - val_accuracy: 0.8440\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9904\n",
      "Epoch 14: accuracy improved from 0.98834 to 0.99042, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.1845 - accuracy: 0.9904 - val_loss: 0.6190 - val_accuracy: 0.8460\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9904\n",
      "Epoch 15: accuracy did not improve from 0.99042\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.1727 - accuracy: 0.9904 - val_loss: 0.6101 - val_accuracy: 0.8560\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9933\n",
      "Epoch 16: accuracy improved from 0.99042 to 0.99327, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 54s 2s/step - loss: 0.1628 - accuracy: 0.9933 - val_loss: 0.6281 - val_accuracy: 0.8520\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9940\n",
      "Epoch 17: accuracy improved from 0.99327 to 0.99404, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.1517 - accuracy: 0.9940 - val_loss: 0.6433 - val_accuracy: 0.8420\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.9935\n",
      "Epoch 18: accuracy did not improve from 0.99404\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.1520 - accuracy: 0.9935 - val_loss: 0.6123 - val_accuracy: 0.8400\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9951\n",
      "Epoch 19: accuracy improved from 0.99404 to 0.99508, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 55s 2s/step - loss: 0.1373 - accuracy: 0.9951 - val_loss: 0.6247 - val_accuracy: 0.8420\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9972\n",
      "Epoch 20: accuracy improved from 0.99508 to 0.99715, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.1235 - accuracy: 0.9972 - val_loss: 0.6589 - val_accuracy: 0.8340\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9969\n",
      "Epoch 21: accuracy did not improve from 0.99715\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.1216 - accuracy: 0.9969 - val_loss: 0.6784 - val_accuracy: 0.8340\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9956\n",
      "Epoch 22: accuracy did not improve from 0.99715\n",
      "31/31 [==============================] - 50s 2s/step - loss: 0.1195 - accuracy: 0.9956 - val_loss: 0.6534 - val_accuracy: 0.8440\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9964\n",
      "Epoch 23: accuracy did not improve from 0.99715\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.1186 - accuracy: 0.9964 - val_loss: 0.6509 - val_accuracy: 0.8400\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9982\n",
      "Epoch 24: accuracy improved from 0.99715 to 0.99819, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.1058 - accuracy: 0.9982 - val_loss: 0.7028 - val_accuracy: 0.8320\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9984\n",
      "Epoch 25: accuracy improved from 0.99819 to 0.99845, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.1022 - accuracy: 0.9984 - val_loss: 0.6780 - val_accuracy: 0.8360\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9974\n",
      "Epoch 26: accuracy did not improve from 0.99845\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.1019 - accuracy: 0.9974 - val_loss: 0.6752 - val_accuracy: 0.8360\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9984\n",
      "Epoch 27: accuracy did not improve from 0.99845\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.0991 - accuracy: 0.9984 - val_loss: 0.6443 - val_accuracy: 0.8460\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9990\n",
      "Epoch 28: accuracy improved from 0.99845 to 0.99896, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.0932 - accuracy: 0.9990 - val_loss: 0.7022 - val_accuracy: 0.8300\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9987\n",
      "Epoch 29: accuracy did not improve from 0.99896\n",
      "31/31 [==============================] - 48s 2s/step - loss: 0.0910 - accuracy: 0.9987 - val_loss: 0.7765 - val_accuracy: 0.8140\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9940\n",
      "Epoch 30: accuracy did not improve from 0.99896\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.1312 - accuracy: 0.9940 - val_loss: 0.6880 - val_accuracy: 0.8320\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9977\n",
      "Epoch 31: accuracy did not improve from 0.99896\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.0927 - accuracy: 0.9977 - val_loss: 0.6406 - val_accuracy: 0.8440\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9984\n",
      "Epoch 32: accuracy did not improve from 0.99896\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.0858 - accuracy: 0.9984 - val_loss: 0.7104 - val_accuracy: 0.8320\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9987\n",
      "Epoch 33: accuracy did not improve from 0.99896\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.0846 - accuracy: 0.9987 - val_loss: 0.6352 - val_accuracy: 0.8360\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9990\n",
      "Epoch 34: accuracy did not improve from 0.99896\n",
      "31/31 [==============================] - 49s 2s/step - loss: 0.0794 - accuracy: 0.9990 - val_loss: 0.6475 - val_accuracy: 0.8280\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9987\n",
      "Epoch 35: accuracy did not improve from 0.99896\n",
      "31/31 [==============================] - 50s 2s/step - loss: 0.0780 - accuracy: 0.9987 - val_loss: 0.6907 - val_accuracy: 0.8220\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9992\n",
      "Epoch 36: accuracy improved from 0.99896 to 0.99922, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 53s 2s/step - loss: 0.0762 - accuracy: 0.9992 - val_loss: 0.6535 - val_accuracy: 0.8320\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9995\n",
      "Epoch 37: accuracy improved from 0.99922 to 0.99948, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.0742 - accuracy: 0.9995 - val_loss: 0.6648 - val_accuracy: 0.8360\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9997\n",
      "Epoch 38: accuracy improved from 0.99948 to 0.99974, saving model to ../Models/Question_Classification/questions_best.h5\n",
      "31/31 [==============================] - 52s 2s/step - loss: 0.0715 - accuracy: 0.9997 - val_loss: 0.6765 - val_accuracy: 0.8200\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9992\n",
      "Epoch 39: accuracy did not improve from 0.99974\n",
      "31/31 [==============================] - 48s 2s/step - loss: 0.0725 - accuracy: 0.9992 - val_loss: 0.6711 - val_accuracy: 0.8340\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9987\n",
      "Epoch 40: accuracy did not improve from 0.99974\n",
      "31/31 [==============================] - 50s 2s/step - loss: 0.0738 - accuracy: 0.9987 - val_loss: 0.6726 - val_accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18404e7d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10)\n",
    "\n",
    "# Save 'best' model\n",
    "model_path = '../Models/Question_Classification/'\n",
    "checkpoint = ModelCheckpoint(model_path + 'questions_best.h5',  # Save the model to a file named 'model-<epoch_number>.h5'\n",
    "                             monitor='accuracy',      # Monitor validation loss\n",
    "                             verbose=1,               # Verbosity mode: 1 = print progress bar, 0 = silent\n",
    "                             save_best_only=True,     # Only save the model if 'val_loss' has improved\n",
    "                             mode='auto')             # Mode: 'auto' decides whether to maximize or minimize 'val_loss' based on its name ('loss' should be minimized, 'acc' should be maximized)\n",
    "\n",
    "\n",
    "model.fit(X_train_padded, \n",
    "          y_train, \n",
    "          epochs=num_epochs, \n",
    "          batch_size=batch_size, \n",
    "          shuffle=True, \n",
    "          validation_data = (X_val_padded, y_val), \n",
    "          callbacks = [early_stopping, checkpoint], \n",
    "          workers = 4)\n",
    "\n",
    "# Save latest model\n",
    "save_path = model_path + 'questions_last.h5'\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "load_path = '../Models/Question_Classification/questions_best.h5'\n",
    "loaded_model = load_model(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 69ms/step - loss: 0.8160 - accuracy: 0.8277\n",
      "Test Loss: 0.8159940242767334, Test Accuracy: 0.8276810050010681\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
